"""
æ™ºæ…§æ¸¯èˆªAIåŠ©æ‰‹ - ä¸»æœåŠ¡æ–‡ä»¶
"""
import json
from datetime import datetime
from typing import Dict, List, Any, Optional

try:
    from fastapi import FastAPI
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel
    import uvicorn
except ImportError as e:
    print(f"ç¼ºå°‘ä¾èµ–: {e}")
    print("è¯·è¿è¡Œ: pip install fastapi uvicorn pydantic")
    exit(1)

# AIé…ç½®
AI_CONFIG = {
    "api_key": "sk-reoHRL3C7a1VeXLgMYgbZ9p3aqUeuQUUKduSzBSrsmiO9DUS",
    "base_url": "https://api.chatfire.cn/v1",
    "model": "gpt-3.5-turbo"
}

# åˆå§‹åŒ–AIå®¢æˆ·ç«¯
try:
    from openai import OpenAI
    
    ai_client = OpenAI(
        api_key=AI_CONFIG["api_key"],
        base_url=AI_CONFIG["base_url"]
    )
    AI_AVAILABLE = True
    print(f"âœ… AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ - {AI_CONFIG['base_url']}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {AI_CONFIG['model']}")
except ImportError as e:
    AI_AVAILABLE = False
    ai_client = None
    print(f"âš ï¸ OpenAIåº“æœªå®‰è£…: {e}")
except Exception as e:
    AI_AVAILABLE = False
    ai_client = None
    print(f"âŒ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="æ™ºæ…§æ¸¯èˆªAIåŠ©æ‰‹",
    description="åŸºäºç¬¬ä¸‰æ–¹AIçš„æ¸¯å£ç‰©èµ„ç®¡ç†æ™ºèƒ½é—®ç­”æœåŠ¡",
    version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    message_id: str
    response: str
    data: Optional[Any] = None
    suggestions: List[str] = []
    session_id: str
    timestamp: str

class QuickAction(BaseModel):
    id: str
    title: str
    query: str
    description: str
    category: str = "inventory"
    icon: str = "QuestionCircleOutlined"

# æ¸¯å£ç‰©èµ„æ•°æ®
MOCK_DATA = {
    "materials": [
        {"name": "èµ·é‡æœº", "category": "machinery", "quantity": 15, "location": "Aç å¤´"},
        {"name": "å‰è½¦", "category": "machinery", "quantity": 28, "location": "Aç å¤´"},
        {"name": "å®‰å…¨å¸½", "category": "safety", "quantity": 150, "location": "1å·ä»“åº“"},
        {"name": "æ‰³æ‰‹", "category": "tools", "quantity": 45, "location": "å·¥å…·ä»“åº“"},
        {"name": "ç›‘æ§æ‘„åƒå¤´", "category": "electronics", "quantity": 32, "location": "Bç å¤´"},
        {"name": "æ‹–è½¦", "category": "machinery", "quantity": 12, "location": "Cç å¤´"},
        {"name": "é˜²æŠ¤æœ", "category": "safety", "quantity": 80, "location": "2å·ä»“åº“"},
        {"name": "ç”µé’»", "category": "tools", "quantity": 25, "location": "å·¥å…·ä»“åº“"},
    ],
    "transactions": [
        {"id": "TXN001", "type": "å…¥åº“", "material": "èµ·é‡æœº", "quantity": 2, "location": "Aç å¤´", "operator": "å¼ ä¸‰", "date": "2024-01-15"},
        {"id": "TXN002", "type": "å‡ºåº“", "material": "å‰è½¦", "quantity": 3, "location": "Aç å¤´", "operator": "æå››", "date": "2024-01-15"},
        {"id": "TXN003", "type": "å…¥åº“", "material": "å®‰å…¨å¸½", "quantity": 50, "location": "1å·ä»“åº“", "operator": "ç‹äº”", "date": "2024-01-14"},
    ]
}

def build_system_prompt() -> str:
    """æ„å»ºAIç³»ç»Ÿæç¤ºè¯"""
    return f"""
ä½ æ˜¯æ™ºæ…§æ¸¯èˆªAIæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºæ¸¯å£ç‰©èµ„ç®¡ç†ç³»ç»Ÿæä¾›æœåŠ¡ã€‚

## ç³»ç»Ÿæ•°æ®
### ç‰©èµ„ä¿¡æ¯
{json.dumps(MOCK_DATA['materials'], ensure_ascii=False, indent=2)}

### äº¤æ˜“è®°å½•
{json.dumps(MOCK_DATA['transactions'], ensure_ascii=False, indent=2)}

## å›ç­”æ ¼å¼è¦æ±‚
è¯·ä½¿ç”¨ç¾è§‚çš„Markdownæ ¼å¼å›ç­”ï¼ŒåŒ…æ‹¬ï¼š

### ğŸ“Š æ•°æ®å±•ç¤ºæ ¼å¼
- ä½¿ç”¨è¡¨æ ¼å±•ç¤ºç»“æ„åŒ–æ•°æ®
- ä½¿ç”¨åˆ—è¡¨å±•ç¤ºè¦ç‚¹ä¿¡æ¯
- ä½¿ç”¨é€‚å½“çš„emojiå›¾æ ‡å¢å¼ºå¯è¯»æ€§
- ä½¿ç”¨æ ‡é¢˜å’Œåˆ†æ®µç»„ç»‡å†…å®¹

### ğŸ“‹ è¡¨æ ¼æ ¼å¼ç¤ºä¾‹
å¯¹äºäº¤æ˜“è®°å½•ï¼Œä½¿ç”¨è¡¨æ ¼æ ¼å¼ï¼š
| äº¤æ˜“ID | ç±»å‹ | ç‰©èµ„ | æ•°é‡ | åœ°ç‚¹ | æ“ä½œå‘˜ | æ—¥æœŸ |
|--------|------|------|------|------|------|------|
| TXN001 | å…¥åº“ | èµ·é‡æœº | 2å° | Aç å¤´ | å¼ ä¸‰ | 2024-01-15 |

### ğŸ“ åˆ—è¡¨æ ¼å¼ç¤ºä¾‹
å¯¹äºåº“å­˜æ¦‚å†µï¼Œä½¿ç”¨åˆ†ç±»åˆ—è¡¨ï¼š
## ğŸ“¦ åº“å­˜æ¦‚å†µ
- **ğŸ—ï¸ æœºæ¢°è®¾å¤‡**: èµ·é‡æœº15å°ã€å‰è½¦28å°
- **ğŸ›¡ï¸ å®‰å…¨ç”¨å“**: å®‰å…¨å¸½150é¡¶ã€é˜²æŠ¤æœ80å¥—
- **ğŸ”§ å·¥å…·è®¾å¤‡**: æ‰³æ‰‹45æŠŠã€ç”µé’»25å°

### ğŸ¯ é‡è¦æç¤º
- äº¤æ˜“è®°å½•å¿…é¡»ä½¿ç”¨è¡¨æ ¼æ ¼å¼å±•ç¤º
- åº“å­˜ä¿¡æ¯ä½¿ç”¨åˆ†ç±»åˆ—è¡¨å±•ç¤º
- åˆ†æç»“æœä½¿ç”¨æ ‡é¢˜åˆ†æ®µç»„ç»‡
- é€‚å½“ä½¿ç”¨emojiå¢å¼ºå¯è¯»æ€§

## å›ç­”è§„åˆ™
1. **å‡†ç¡®æ€§**: åŸºäºæä¾›çš„æ•°æ®ç»™å‡ºå‡†ç¡®å›ç­”
2. **æ ¼å¼åŒ–**: ä½¿ç”¨Markdownæ ¼å¼ç¾åŒ–å±•ç¤º
3. **ç»“æ„åŒ–**: ç”¨è¡¨æ ¼ã€åˆ—è¡¨ç­‰æ–¹å¼ç»„ç»‡ä¿¡æ¯
4. **å¯è¯»æ€§**: æ·»åŠ emojiå’Œæ ‡é¢˜æå‡é˜…è¯»ä½“éªŒ
5. **ä¸“ä¸šæ€§**: ä¿æŒæ¸¯å£ç‰©èµ„ç®¡ç†çš„ä¸“ä¸šæœ¯è¯­

è¯·å§‹ç»ˆä½¿ç”¨Markdownæ ¼å¼å›ç­”ï¼Œè®©ä¿¡æ¯å±•ç¤ºæ›´åŠ ç¾è§‚å’Œæ˜“è¯»ã€‚
"""

async def process_with_ai(user_input: str) -> Dict[str, Any]:
    """AIå¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    if not AI_AVAILABLE or not ai_client:
        return {
            "response": "æŠ±æ­‰ï¼ŒAIæœåŠ¡å½“å‰ä¸å¯ç”¨ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–è”ç³»ç®¡ç†å‘˜ã€‚",
            "data": None,
            "suggestions": ["ç¨åé‡è¯•", "æ£€æŸ¥ç½‘ç»œè¿æ¥", "è”ç³»æŠ€æœ¯æ”¯æŒ"],
            "ai_powered": False
        }
    
    try:
        response = ai_client.chat.completions.create(
            model=AI_CONFIG["model"],
            messages=[
                {"role": "system", "content": build_system_prompt()},
                {"role": "user", "content": user_input}
            ],
            max_tokens=500,
            temperature=0.3,
            timeout=30
        )
        
        if hasattr(response, 'choices') and len(response.choices) > 0:
            ai_response = response.choices[0].message.content
            
            return {
                "response": ai_response,
                "data": None,
                "suggestions": ["æŸ¥çœ‹åº“å­˜æ€»è§ˆ", "æœ€è¿‘çš„äº¤æ˜“è®°å½•", "æœç´¢ç‰¹å®šç‰©èµ„"],
                "ai_powered": True
            }
        else:
            raise Exception("AIå“åº”æ ¼å¼ä¸æ­£ç¡®")
        
    except Exception as e:
        error_str = str(e)
        if "<!DOCTYPE html>" in error_str or "<html" in error_str:
            error_msg = "AIæœåŠ¡é…ç½®é”™è¯¯ï¼Œè¯·æ£€æŸ¥APIç«¯ç‚¹è®¾ç½®ã€‚"
        else:
            error_msg = f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)[:100]}"
        
        return {
            "response": error_msg,
            "data": None,
            "suggestions": ["ç¨åé‡è¯•", "æ£€æŸ¥ç½‘ç»œè¿æ¥", "è”ç³»æŠ€æœ¯æ”¯æŒ"],
            "ai_powered": False
        }

# APIè·¯ç”±
@app.get("/")
async def root():
    return {
        "message": "æ™ºæ…§æ¸¯èˆªAIåŠ©æ‰‹API",
        "version": "1.0.0",
        "status": "running",
        "ai_status": "å·²è¿æ¥" if AI_AVAILABLE else "ä¸å¯ç”¨"
    }

@app.get("/health")
async def health():
    return {"status": "healthy", "ai_available": AI_AVAILABLE}

@app.post("/api/chat/message", response_model=ChatResponse)
async def chat_message(request: ChatRequest):
    try:
        message_id = f"msg_{int(datetime.now().timestamp())}"
        session_id = request.session_id or f"session_{int(datetime.now().timestamp())}"
        
        result = await process_with_ai(request.message)
        
        return ChatResponse(
            message_id=message_id,
            response=result["response"],
            data=result["data"],
            suggestions=result["suggestions"],
            session_id=session_id,
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        return ChatResponse(
            message_id=f"msg_{int(datetime.now().timestamp())}",
            response=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}",
            data=None,
            suggestions=["ç¨åé‡è¯•", "æ£€æŸ¥ç½‘ç»œè¿æ¥", "è”ç³»æŠ€æœ¯æ”¯æŒ"],
            session_id=request.session_id or f"session_{int(datetime.now().timestamp())}",
            timestamp=datetime.now().isoformat()
        )

@app.get("/api/chat/quick-actions")
async def quick_actions():
    return [
        QuickAction(id="inventory", title="åº“å­˜æ€»è§ˆ", query="åº“å­˜æ€»è§ˆ", description="æŸ¥çœ‹æ•´ä½“åº“å­˜ç»Ÿè®¡"),
        QuickAction(id="analysis", title="æ™ºèƒ½åˆ†æ", query="åˆ†ææ¸¯å£ç‰©èµ„åˆ†å¸ƒæƒ…å†µ", description="AIåˆ†æç‰©èµ„çŠ¶å†µ"),
        QuickAction(id="port_a", title="Aç å¤´åº“å­˜", query="Aç å¤´æœ‰å¤šå°‘ç‰©å“", description="æŸ¥çœ‹Aç å¤´ç‰©èµ„"),
        QuickAction(id="outbound", title="å‡ºåº“è®°å½•", query="æœ€è¿‘çš„å‡ºåº“è®°å½•", description="æŸ¥çœ‹å‡ºåº“æƒ…å†µ"),
        QuickAction(id="inbound", title="å…¥åº“è®°å½•", query="æœ€è¿‘çš„å…¥åº“è®°å½•", description="æŸ¥çœ‹å…¥åº“æƒ…å†µ"),
        QuickAction(id="search", title="æœç´¢èµ·é‡æœº", query="æœç´¢èµ·é‡æœº", description="æŸ¥æ‰¾è®¾å¤‡ä¿¡æ¯")
    ]

@app.get("/api/chat/suggestions")
async def suggestions():
    return {
        "suggestions": [
            "Aç å¤´æœ‰å¤šå°‘ç‰©å“ï¼Ÿ",
            "åº“å­˜æ€»è§ˆ",
            "åˆ†ææ¸¯å£ç‰©èµ„åˆ†å¸ƒæƒ…å†µ",
            "æœ€è¿‘çš„å‡ºåº“è®°å½•",
            "ç»™æˆ‘ä¸€äº›åº“å­˜ç®¡ç†å»ºè®®",
            "æœç´¢èµ·é‡æœº",
            "æ¸¯å£å®‰å…¨è®¾å¤‡æ˜¯å¦å……è¶³ï¼Ÿ",
            "ä»Šå¤©çš„äº¤æ˜“è®°å½•"
        ]
    }

@app.get("/api/chat/status")
async def status():
    return {
        "status": "healthy",
        "ai_service": AI_AVAILABLE,
        "ai_type": f"ç¬¬ä¸‰æ–¹AI {AI_CONFIG['model']}" if AI_AVAILABLE else "AIä¸å¯ç”¨",
        "ai_provider": f"ç¬¬ä¸‰æ–¹AI ({AI_CONFIG['base_url']})" if AI_AVAILABLE else "æ— ",
        "model": AI_CONFIG['model'],
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨æ™ºæ…§æ¸¯èˆªAIåŠ©æ‰‹...")
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://localhost:8001")
    print(f"ğŸ¤– AIçŠ¶æ€: {'âœ… å·²è¿æ¥' if AI_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")
    print(f"ğŸ”— APIæ–‡æ¡£: http://localhost:8001/docs")
    print("=" * 50)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info"
    )
